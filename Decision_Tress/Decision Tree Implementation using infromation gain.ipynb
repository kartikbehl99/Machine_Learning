{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydotplus\n",
    "import pandas as pd\n",
    "import sklearn.datasets as Datasets\n",
    "from sklearn import tree\n",
    "from sklearn import model_selection as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function to convert continuos values to discrete values\n",
    "def makeLabelled(column):\n",
    "    mean = column.mean()\n",
    "    for i in range (0,len(column)):\n",
    "        column[i] = int(column[i]>=mean) \n",
    "    return column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Iris Dataset to change it to Labeled DataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = Datasets.load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.values\n",
    "Y = iris.target\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As iris dataset has continuous values, we will convert them into discrete nunbers\n",
    "for i in range(0,X.shape[-1]):\n",
    "    X[:,i] = makeLabelled(X[:,i])\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
    "clf.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(clf,out_file= None)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"irisDecisionTree.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function calculates entropy\n",
    "def entropy(Y):\n",
    "    classes = set(Y)\n",
    "    #print(\"Different Classes are = \",classes)\n",
    "    value = 0\n",
    "    for i in classes:\n",
    "        p = (len(Y[Y==i])/len(Y))\n",
    "        value = value - (p*np.log2(p))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding gain ration for a selected feature\n",
    "def findGainRatio(X,Y,selectedFeature):\n",
    "    differentLabels = set(X[:,selectedFeature])\n",
    "    entropyBeforeSplitting = entropy(Y)\n",
    "    entropyAfterSplitting = 0\n",
    "    splitInfo = 0\n",
    "    for i in differentLabels:\n",
    "        newNodeY = Y[(X[:,selectedFeature] == i)]\n",
    "        weightOfSamples = (len(newNodeY)/len(Y))\n",
    "        entropyAfterSplitting = entropyAfterSplitting + (weightOfSamples*entropy(newNodeY))\n",
    "        splitInfo = splitInfo - (weightOfSamples*np.log2(weightOfSamples))\n",
    "    #print(\"Entropy Before Splitting = \",entropyBeforeSplitting)\n",
    "    #print(\"Entropy After Splitting = \",entropyAfterSplitting)\n",
    "    gain = entropyBeforeSplitting - entropyAfterSplitting\n",
    "    gainRatio = gain#/splitInfo\n",
    "    #print(\"gain is = \",gain)\n",
    "    #print(\"split info is = \",splitInfo)\n",
    "    #print(\"gain Ratio is = \",gainRatio)\n",
    "    return gainRatio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will count of samples for each class.\n",
    "def printClassification(Y):\n",
    "    classes = set(Y)\n",
    "    for i in classes:\n",
    "        print(\"Count of \",i,\" = \",len(Y[Y==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create and print Decision tree. This function prints the selected feature at every step and corresponding entropy.\n",
    "def printSplitsDFS(X,Y,available_features):\n",
    "    print(\" \")\n",
    "    printClassification(Y)\n",
    "    print(\"Current Entropy is = \",entropy(Y))\n",
    "    if(available_features == 0 or (entropy(Y) == 0)):\n",
    "        print(\"Reached leaf Node\")\n",
    "        return\n",
    "    selectedFeature = 0\n",
    "    max_value = -float('inf')\n",
    "    #finding gain ratio for all possible features on which we can split and then choosing the feature with maximum gain.\n",
    "    for i in range(0,X.shape[-1]):\n",
    "        value = findGainRatio(X,Y,i)\n",
    "        if(value >= max_value):\n",
    "            selectedFeature = i\n",
    "            max_value = value\n",
    "    print(\"Splitting on feature \",selectedFeature)\n",
    "    #Find all possible unique labels for the selected feature.\n",
    "    differentLabels = set(X[:,selectedFeature])\n",
    "    for i in differentLabels:\n",
    "        newDataSamples = (X[:,selectedFeature] == i)\n",
    "        newX = X[newDataSamples]\n",
    "        newY = Y[newDataSamples]\n",
    "        printSplitsDFS(newX,newY,available_features-1)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printSplitsDFS(X,Y,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = np.array([0,1,1,0])\n",
    "# printSplitsDFS(X,Y,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
